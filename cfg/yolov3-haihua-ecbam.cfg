[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=16
subdivisions=1
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

# output_filters的索引比module_list中+1
# 因此module_list的index=mdef的index
# medf_index=0
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# Downsample

# mdef_index=1
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

# mdef_index =2
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

# mdef_index=3
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=None

# mdef_index=4
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=5
# routs[0] = 1  # self.routs[i]是True或者False掩码，out会根据self.routs[i]为True或者false将module的输出 x append进out
# 这里routs[i]=n仅表示的是module_list中索引为第n个module的输出会被实际append进out
[shortcut]
from=-4
activation=linear

# Downsample
# mdef_index=6
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

# mdef_index=7
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# mdef_index=8
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=None

# mdef_index=9
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=10
# routs[1] = 6
[shortcut]
from=-4
activation=linear

# mdef_index=11
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# mdef_index=12
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=None

# mdef_index=13
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=14
# routs[2] = 10
[shortcut]
from=-4
activation=linear

# Downsample
# mdef_index=15
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

# mdef_index=16
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=17
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=18
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=19
# routs[3] = 15
[shortcut]
from=-4
activation=linear

# mdef_index=20
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=21
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=22
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=23
# routs[4]=19
[shortcut]
from=-4
activation=linear

# mdef_index=24
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=25
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=26
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=27
# routs[5]=23
[shortcut]
from=-4
activation=linear

# mdef_index=28
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=29
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=30
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=31
# routs[6]=27
[shortcut]
from=-4
activation=linear

# mdef_index=32
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=33
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=34
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=35
# routs[7]=31
[shortcut]
from=-4
activation=linear

# mdef_index=36
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=37
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=38
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=39
# routs[8]=35
[shortcut]
from=-4
activation=linear

# mdef_index=40
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=41
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=42
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=43
# routs[9]=39
[shortcut]
from=-4
activation=linear

# mdef_index=44
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=45      36
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=None

# mdef_index=46
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=47
# routs[10]=43
[shortcut]
from=-4
activation=linear

# Downsample

# mdef_index=48
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

# mdef_index=49
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=50
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=51
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=52
# routs[11]=48
[shortcut]
from=-4
activation=linear

# mdef_index=53
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=54
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=55
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=56
# routs[12]=52
[shortcut]
from=-4
activation=linear

# mdef_index=57
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=58
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=59
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=60
# routs[13]=56
[shortcut]
from=-4
activation=linear

# mdef_index=61
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=62
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=63
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=64
# routs[14]=60
[shortcut]
from=-4
activation=linear

# mdef_index=65
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=66
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=67
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=68  53
# routs[15]=64
[shortcut]
from=-4
activation=linear

# mdef_index=69
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=70
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=71
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=72
# routs[16]=68
[shortcut]
from=-4
activation=linear

# mdef_index=73
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=74
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=75
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=76
# routs[17]=72
[shortcut]
from=-4
activation=linear

# mdef_index=77
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=78  61==>79
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=None

# mdef_index=79
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=80
# routs[18]=76
[shortcut]
from=-4
activation=linear

# Downsample

# mdef_index=81
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky

# mdef_index=82
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# mdef_index=83
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=None

# mdef_index=84
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=85
# routs[19]=81
[shortcut]
from=-4
activation=linear

# mdef_index=86
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# mdef_index=87
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=None

# mdef_index=88
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=89
# routs[20]=85
[shortcut]
from=-4
activation=linear

# mdef_index=90
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# mdef_index=91
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=None

# mdef_index=92
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=93
# routs[21]=89
[shortcut]
from=-4
activation=linear

# mdef_index=94
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# mdef_index=95
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=None
# 在residual结构中，ecbam前一个卷积层的激活函数没有，意味着我们需要将ecbam和cbam一样安放在
# 一个残差快中的跳连之前

# mdef_index=96######################################
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=97
# routs[22]=93
[shortcut]
from=-4
activation=linear


######################

# mdef_index=98
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# mdef_index=99
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

# mdef_index=100
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# mdef_index=101  # 同时这里也可以不需要再
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=102
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

# yolo-layer1检测头

# mdef_index=103
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# mdef_index=104
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

# mdef_index=105
# routs[23]=105
[convolutional]
size=1
stride=1
pad=1
filters=1045
activation=linear


# mdef_index=106
[yolo]
mask = 10,11,12,13,14
anchors = 17,17,  34,35,  66,34,  47,54,  65,63,  52,97,  101,63,  81,86,  111,105,  83,141,  169,92,  132,135,  192,154,  156,211,  240,219
classes=204
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

# mdef_index=107
# routs[24]=103
[route]
layers = -4

# mdef_index=108
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=109
[upsample]
stride=2

# mdef_index=110
# routs[25]= 109, 61  这里不能再使用61了!!
[route]
layers = -1, 79


# mdef_index=111
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=112
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

# mdef_index=113
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=114
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=115
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

# yolo-layer2检测头

# mdef_index=116
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# mdef_index=117
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

# mdef_index=118
# routs[26]=118  这里存储的意义？
[convolutional]
size=1
stride=1
pad=1
filters=1045
activation=linear

# mdef_index=119
[yolo]
mask = 5,6,7,8,9
anchors = 17,17,  34,35,  66,34,  47,54,  65,63,  52,97,  101,63,  81,86,  111,105,  83,141,  169,92,  132,135,  192,154,  156,211,  240,219
classes=204
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1


# mdef_index=120
# routs[27]=116
[route]
layers = -4

# mdef_index=121 这里是不需要增加ecbam的，因为这里是将之前的特征图拿过来，并且对通道信息整合
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=122
[upsample]
stride=2

# mdef_index=123
# routs[28]=122, 36, 将module_list中index=36的浅层信息链接过来
[route]
layers = -1, 46


# mdef_index=124
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=125
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

# mdef_index=126
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=127  当时，这里放ecbam的初衷是为了在检测头中也加入ecbam
[ecbam]
ecakernelsize = 7
kernelsize = 7

# mdef_index=128
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

# yolo-layer3检测头

# mdef_index=129
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# mdef_index=130
[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

# mdef_index=131
# routs[29]=131
[convolutional]
size=1
stride=1
pad=1
filters=1045
activation=linear

# mdef_index=132
[yolo]
mask = 0,1,2,3,4
anchors = 17,17,  34,35,  66,34,  47,54,  65,63,  52,97,  101,63,  81,86,  111,105,  83,141,  169,92,  132,135,  192,154,  156,211,  240,219
classes=204
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1